{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmethratta/Poliscope/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers"
      ],
      "metadata": {
        "id": "bafN0lgvPKim",
        "outputId": "246b24ec-5a52-4b29-e4e9-a884624bd874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "tc_vHiR0PJ6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e06a14-4233-4c21-a4b0-35d0edf85152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-14 22:19:52--  https://raw.githubusercontent.com/lmethratta/Poliscope/refs/heads/main/twinviews-13k.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3063233 (2.9M) [text/plain]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "\rdata.csv              0%[                    ]       0  --.-KB/s               \rdata.csv            100%[===================>]   2.92M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-04-14 22:19:52 (81.7 MB/s) - ‘data.csv’ saved [3063233/3063233]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "!wget -O data.csv \"https://raw.githubusercontent.com/lmethratta/Poliscope/refs/heads/main/twinviews-13k.csv\"\n",
        "\n",
        "# Load CSV into a DataFrame\n",
        "df = pd.read_csv(\"data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a regression dataset with scores from -1 to 1\n",
        "df_left = df[['l']].rename(columns={'l': 'text'})\n",
        "df_left['bias_score'] = -1  # Left bias\n",
        "\n",
        "df_right = df[['r']].rename(columns={'r': 'text'})\n",
        "df_right['bias_score'] = 1  # Right bias\n",
        "\n",
        "# Combine datasets and shuffle\n",
        "df_combined = pd.concat([df_left, df_right]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Split into train and validation\n",
        "train_df, val_df = train_test_split(df_combined, test_size=0.1, random_state=42)\n",
        "\n",
        "# Load pre-trained tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n"
      ],
      "metadata": {
        "id": "aG6r9d3cPeWm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def average_precision_at_k(relevance_scores, k):\n",
        "    \"\"\"Computes Average Precision at K\"\"\"\n",
        "    relevance_scores = np.array(relevance_scores)[:k]\n",
        "    num_relevant = np.sum(relevance_scores)\n",
        "    if num_relevant == 0:\n",
        "        return 0.0\n",
        "    cumulative_precision = [\n",
        "        np.sum(relevance_scores[:i+1]) / (i+1) for i in range(len(relevance_scores))\n",
        "    ]\n",
        "    return np.sum(cumulative_precision * relevance_scores) / num_relevant\n",
        "\n",
        "def mean_average_precision(relevance_scores_list, k=10):\n",
        "    \"\"\"Computes Mean Average Precision (MAP)\"\"\"\n",
        "    return np.mean([average_precision_at_k(scores, k) for scores in relevance_scores_list])\n",
        "\n",
        "def dcg_at_k(relevance_scores, k):\n",
        "    \"\"\"Computes Discounted Cumulative Gain at K\"\"\"\n",
        "    relevance_scores = np.array(relevance_scores)[:k]\n",
        "    return np.sum(relevance_scores / np.log2(np.arange(2, len(relevance_scores) + 2)))\n",
        "\n",
        "def ndcg_at_k(relevance_scores, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG)\"\"\"\n",
        "    ideal_relevance = sorted(relevance_scores, reverse=True)  # Ideal DCG\n",
        "    return dcg_at_k(relevance_scores, k) / (dcg_at_k(ideal_relevance, k) + 1e-10)\n",
        "\n",
        "# Example usage:\n",
        "relevance_scores_list = [\n",
        "    [1, 0, 1, 1, 0],  # Example query results: 1 = relevant, 0 = non-relevant\n",
        "    [1, 1, 0, 0, 1],\n",
        "]\n",
        "\n",
        "map_score = mean_average_precision(relevance_scores_list, k=5)\n",
        "ndcg_score = np.mean([ndcg_at_k(scores, k=5) for scores in relevance_scores_list])\n",
        "\n",
        "print(f\"MAP: {map_score:.4f}\")\n",
        "print(f\"NDCG: {ndcg_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "Mv7sEbRJPvVF",
        "outputId": "eec3cfc5-9fbc-4efe-c561-17fd028a69f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP: 0.8361\n",
            "NDCG: 0.9265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create torch datasets\n",
        "class PoliticalBiasDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, tokenizer):\n",
        "        self.encodings = tokenizer(dataframe[\"text\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        self.labels = torch.tensor(dataframe[\"bias_score\"].values, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PoliticalBiasDataset(train_df, tokenizer)\n",
        "val_dataset = PoliticalBiasDataset(val_df, tokenizer)"
      ],
      "metadata": {
        "id": "WnWSX1cpQY4M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model for regression (1 output for the bias score)\n",
        "# API Key: 22837c95f026f63e3b60016c1de298e170d484cd\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "1sFojso3VijW",
        "outputId": "157a99b1-de03-44a2-9b1e-d58a6c23288b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrombuski\u001b[0m (\u001b[33mrombuski-northeastern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250414_222020-fudlfj8g</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rombuski-northeastern/huggingface/runs/fudlfj8g' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rombuski-northeastern/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rombuski-northeastern/huggingface' target=\"_blank\">https://wandb.ai/rombuski-northeastern/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rombuski-northeastern/huggingface/runs/fudlfj8g' target=\"_blank\">https://wandb.ai/rombuski-northeastern/huggingface/runs/fudlfj8g</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='593' max='4677' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 593/4677 00:43 < 05:00, 13.57 it/s, Epoch 0.38/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-611da5df341c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2512\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5242\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5243\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5245\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m                 \u001b[0;31m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mskip_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         return type(tensor)(\n\u001b[0;32m--> 183\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    182\u001b[0m         return type(tensor)(\n\u001b[1;32m    183\u001b[0m             {\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_keys\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             }\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict bias score for new text\n",
        "def predict_bias(text, model, tokenizer, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "    # Move model to the specified device\n",
        "    model.to(device)\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Move input tensors to the same device as the model\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    return outputs.logits.item()  # Returns a score between -1 and 1\n",
        "\n",
        "# Example usage\n",
        "test_texts = [\n",
        "    \"Abortion should be free\",\n",
        "    \"Lower taxes and less regulation will stimulate economic growth.\",\n",
        "    \"Healthcare should be a basic right for all citizens.\"\n",
        "]\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "for text in test_texts:\n",
        "    score = predict_bias(text, model, tokenizer)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Bias score: {score:.2f}\")\n",
        "    print(f\"Political leaning: {'Left' if score < 0 else 'Right'}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "6VdV65aWXUq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525aba14-4af4-418e-e135-531ee4e94d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Text: Abortion should be free\n",
            "Bias score: -1.02\n",
            "Political leaning: Left\n",
            "--------------------------------------------------\n",
            "Text: Lower taxes and less regulation will stimulate economic growth.\n",
            "Bias score: 0.99\n",
            "Political leaning: Right\n",
            "--------------------------------------------------\n",
            "Text: Healthcare should be a basic right for all citizens.\n",
            "Bias score: -1.03\n",
            "Political leaning: Left\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_accuracy(model, data_loader):\n",
        "#     model.eval()\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     total_loss = 0\n",
        "#     criterion = nn.MSELoss()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, labels in data_loader:\n",
        "#             inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs).squeeze()\n",
        "\n",
        "#             # Convert regression output to -1 or 1\n",
        "#             predictions = torch.where(outputs >= 0, torch.tensor(1.0, device=device), torch.tensor(-1.0, device=device))\n",
        "\n",
        "#             correct += (predictions == labels).sum().item()\n",
        "#             total += labels.size(0)\n",
        "\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             total_loss += loss.item()\n",
        "\n",
        "#     accuracy = correct / total * 100\n",
        "#     return total_loss / len(data_loader), accuracy\n",
        "\n",
        "\n",
        "# # Compute validation loss & accuracy\n",
        "# val_loss, val_accuracy = compute_accuracy(model, val_loader)\n",
        "# print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "# print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "p1gA8mwIXN3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Part 1: Logistic Regression Classifier on TF-IDF ===\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# For demonstration, assume df_combined is already defined and contains columns 'text' and 'bias_score'\n",
        "# Create a binary label: left bias (<0) maps to 0 and right bias (>=0) maps to 1.\n",
        "df_combined['binary_label'] = df_combined['bias_score'].apply(lambda x: 0 if x < 0 else 1)\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_df_lr, val_df_lr = train_test_split(df_combined, test_size=0.1, random_state=42)\n",
        "\n",
        "# Initialize the TF-IDF vectorizer (this lowercases text and removes English stopwords)\n",
        "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_df_lr['text'])\n",
        "X_val = vectorizer.transform(val_df_lr['text'])\n",
        "y_train = train_df_lr['binary_label']\n",
        "y_val = val_df_lr['binary_label']  # Use the validation labels here!\n",
        "\n",
        "# Train the logistic regression classifier\n",
        "lr_model = LogisticRegression(max_iter=200)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate on the validation set\n",
        "y_pred = lr_model.predict(X_val)\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4FA3My-eHQT",
        "outputId": "fa78ef1a-dead-4c94-b246-d7c789b4b763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97      1374\n",
            "           1       0.96      0.97      0.97      1397\n",
            "\n",
            "    accuracy                           0.97      2771\n",
            "   macro avg       0.97      0.97      0.97      2771\n",
            "weighted avg       0.97      0.97      0.97      2771\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Print out the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Optionally, you can also plot the confusion matrix for a visual perspective:\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Predicted Left (0)\", \"Predicted Right (1)\"],\n",
        "            yticklabels=[\"Actual Left (0)\", \"Actual Right (1)\"])\n",
        "plt.ylabel(\"True label\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "yJfoS6YppaQH",
        "outputId": "fb7040c1-174a-4ae0-f1b9-a3454ce51fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1321   53]\n",
            " [  36 1361]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Part 2: BM25 Relevance Scoring ===\n",
        "# Install rank_bm25 if needed\n",
        "!pip install rank_bm25\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Define a simple preprocessing function to remove punctuation and lowercase the text\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    return text.split()\n",
        "\n",
        "# Build the BM25 corpus: tokenize each document in df_combined\n",
        "corpus = [preprocess(doc) for doc in df_combined['text']]\n",
        "bm25 = BM25Okapi(corpus)\n",
        "\n",
        "# For a sample query, preprocess it similarly:\n",
        "query = \"healthcare for all citizens\"\n",
        "query_tokens = preprocess(query)\n",
        "\n",
        "# Calculate BM25 relevance scores for each document in the corpus\n",
        "relevance_scores = bm25.get_scores(query_tokens)\n",
        "print(\"BM25 relevance scores computed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82nlT-gKeHZ7",
        "outputId": "e980c0b6-947d-4559-811d-d099db1f3ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "BM25 relevance scores computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Part 3: Combine Bias Confidence Scores and BM25 Scores for Ranking ===\n",
        "# Get the bias confidence scores from the logistic regression classifier:\n",
        "# Transform all documents using the TF-IDF vectorizer.\n",
        "X_full = vectorizer.transform(df_combined['text'])\n",
        "# Predict the probability of class '1' (right bias)\n",
        "predicted_probas = lr_model.predict_proba(X_full)[:, 1]\n",
        "\n",
        "# Map probabilities from [0, 1] to a signed bias score in [-1, 1]\n",
        "bias_scores = 2 * predicted_probas - 1\n",
        "\n",
        "# Convert relevance_scores to a NumPy array if it isn't already\n",
        "relevance_scores = np.array(relevance_scores)\n",
        "\n",
        "# Combine the scores (here we use multiplication as an example)\n",
        "final_scores = relevance_scores * bias_scores\n",
        "\n",
        "# Rank documents based on the combined final score (descending order)\n",
        "ranked_indices = np.argsort(final_scores)[::-1]\n",
        "\n",
        "# Display the top 10 ranked documents\n",
        "print(\"\\nTop 10 Ranked Documents:\")\n",
        "for i, idx in enumerate(ranked_indices[:10], start=1):\n",
        "    doc_text = df_combined.iloc[idx]['text'][:100].replace('\\n', ' ')  # show first 100 characters\n",
        "    print(f\"{i}. Score: {final_scores[idx]:.4f} | Excerpt: {doc_text}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sleIFP_Rgdni",
        "outputId": "2fb48abe-411e-420c-e907-26147be93039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Ranked Documents:\n",
            "1. Score: 8.2660 | Excerpt: Citizens should be responsible for their own healthcare costs....\n",
            "2. Score: 8.1507 | Excerpt: Lowering taxes for all promotes economic growth, incentivizes investment, and benefits all citizens....\n",
            "3. Score: 7.8075 | Excerpt: Lower taxes for everyone stimulate economic growth and benefit all citizens...\n",
            "4. Score: 7.2539 | Excerpt: Free-market competition leads to innovation and affordable healthcare options for all....\n",
            "5. Score: 6.8919 | Excerpt: Free market competition leads to innovation and improves healthcare outcomes for all....\n",
            "6. Score: 6.8874 | Excerpt: Lowering taxes for the wealthy stimulates economic growth and benefits all citizens....\n",
            "7. Score: 6.7561 | Excerpt: Tax cuts for businesses and the wealthy stimulate economic growth and benefit all citizens....\n",
            "8. Score: 6.7025 | Excerpt: Lower taxes for the wealthy incentivize investment, job creation, and economic growth that benefits ...\n",
            "9. Score: 6.6848 | Excerpt: Lower taxes encourage economic growth and individual prosperity, benefiting all citizens....\n",
            "10. Score: 6.2012 | Excerpt: Lowering taxes on the wealthy promotes economic growth and benefits all citizens....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def average_precision_at_k(relevance_scores, k):\n",
        "    \"\"\"Compute Average Precision at K for one query.\"\"\"\n",
        "    relevance_scores = np.array(relevance_scores)[:k]\n",
        "    num_relevant = np.sum(relevance_scores)\n",
        "    if num_relevant == 0:\n",
        "        return 0.0\n",
        "    cumulative_precision = [\n",
        "        np.sum(relevance_scores[:i+1]) / (i+1) for i in range(len(relevance_scores))\n",
        "    ]\n",
        "    return np.sum(cumulative_precision * relevance_scores) / num_relevant\n",
        "\n",
        "def mean_average_precision(relevance_scores_list, k=10):\n",
        "    \"\"\"Compute Mean Average Precision over multiple queries.\"\"\"\n",
        "    return np.mean([average_precision_at_k(scores, k) for scores in relevance_scores_list])\n",
        "\n",
        "def dcg_at_k(relevance_scores, k):\n",
        "    \"\"\"Compute Discounted Cumulative Gain at K.\"\"\"\n",
        "    relevance_scores = np.array(relevance_scores)[:k]\n",
        "    return np.sum(relevance_scores / np.log2(np.arange(2, len(relevance_scores) + 2)))\n",
        "\n",
        "def ndcg_at_k(relevance_scores, k):\n",
        "    \"\"\"Compute Normalized Discounted Cumulative Gain at K.\"\"\"\n",
        "    ideal_relevance = sorted(relevance_scores, reverse=True)  # highest scores first\n",
        "    return dcg_at_k(relevance_scores, k) / (dcg_at_k(ideal_relevance, k) + 1e-10)\n",
        "\n",
        "\n",
        "# === Sample Evaluation ===\n",
        "# For demonstration, suppose we have a list of queries.\n",
        "sample_queries = [\n",
        "    \"healthcare for all citizens\",\n",
        "    \"tax cuts for economic growth\",\n",
        "    \"environmental policy and climate change\"\n",
        "]\n",
        "\n",
        "# Here we define a helper function to get final ranking scores\n",
        "# using a combination strategy. This example assumes\n",
        "# we already have a BM25 instance (`bm25`), a trained TF-IDF vectorizer,\n",
        "# and a trained logistic regression model `lr_model`.\n",
        "\n",
        "def get_final_scores(query, combination_strategy='multiplicative', alpha=0.5, beta=0.5):\n",
        "    \"\"\"\n",
        "    Compute final ranking scores for the entire corpus given a query.\n",
        "\n",
        "    Parameters:\n",
        "    - query: str, the search query.\n",
        "    - combination_strategy: string, one of 'multiplicative', 'additive', or 'weighted'.\n",
        "    - alpha, beta: weights for the weighted sum combination.\n",
        "\n",
        "    Returns:\n",
        "    - final_scores: NumPy array of combined scores for each document.\n",
        "    \"\"\"\n",
        "    # Preprocess and compute BM25 scores for the query\n",
        "    query_tokens = preprocess(query)\n",
        "    bm25_scores = np.array(bm25.get_scores(query_tokens))\n",
        "\n",
        "    # Obtain bias confidence scores using the logistic regression classifier.\n",
        "    X_full = vectorizer.transform(df_combined['text'])\n",
        "    predicted_probas = lr_model.predict_proba(X_full)[:, 1]\n",
        "    # Map [0, 1] probability to [-1, 1]\n",
        "    bias_scores = 2 * predicted_probas - 1\n",
        "\n",
        "    if combination_strategy == 'multiplicative':\n",
        "        final_scores = bm25_scores * bias_scores\n",
        "    elif combination_strategy == 'additive':\n",
        "        final_scores = bm25_scores + bias_scores\n",
        "    elif combination_strategy == 'weighted':\n",
        "        # You can adjust alpha and beta to weight the relevance and bias scores\n",
        "        final_scores = alpha * bm25_scores + beta * bias_scores\n",
        "    else:\n",
        "        raise ValueError(\"Invalid combination strategy provided.\")\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "\n",
        "# Assume we have some dummy ground truth relevance judgments for these queries.\n",
        "# For each query, create a list of relevance labels (1 for relevant, 0 for non-relevant).\n",
        "# In practice, replace these with your actual judgments.\n",
        "dummy_judgments = {\n",
        "    \"healthcare for all citizens\": [1 if i % 5 == 0 else 0 for i in range(len(df_combined))],\n",
        "    \"tax cuts for economic growth\": [1 if i % 7 == 0 else 0 for i in range(len(df_combined))],\n",
        "    \"environmental policy and climate change\": [1 if i % 11 == 0 else 0 for i in range(len(df_combined))]\n",
        "}\n",
        "\n",
        "# Evaluate each query\n",
        "map_scores = []\n",
        "ndcg_scores = []\n",
        "k = 10  # Evaluate MAP@10 and NDCG@10\n",
        "\n",
        "for query in sample_queries:\n",
        "    final_scores = get_final_scores(query, combination_strategy='multiplicative')\n",
        "    ranked_indices = np.argsort(final_scores)[::-1]\n",
        "\n",
        "    # Generate the relevance list for the ranked order\n",
        "    ranked_relevances = [dummy_judgments[query][idx] for idx in ranked_indices]\n",
        "\n",
        "    ap = average_precision_at_k(ranked_relevances, k)\n",
        "    ndcg = ndcg_at_k(ranked_relevances, k)\n",
        "    map_scores.append(ap)\n",
        "    ndcg_scores.append(ndcg)\n",
        "\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"MAP@{k}: {ap:.4f}, NDCG@{k}: {ndcg:.4f}\\n\")\n",
        "\n",
        "print(f\"Mean MAP@{k}: {np.mean(map_scores):.4f}\")\n",
        "print(f\"Mean NDCG@{k}: {np.mean(ndcg_scores):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSI3iqnjgkKh",
        "outputId": "c5fa0671-0a38-473f-9d17-e6eede363169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'healthcare for all citizens'\n",
            "MAP@10: 0.2250, NDCG@10: 0.1584\n",
            "\n",
            "Query: 'tax cuts for economic growth'\n",
            "MAP@10: 0.1000, NDCG@10: 0.0636\n",
            "\n",
            "Query: 'environmental policy and climate change'\n",
            "MAP@10: 0.0000, NDCG@10: 0.0000\n",
            "\n",
            "Mean MAP@10: 0.1083\n",
            "Mean NDCG@10: 0.0740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define a pipeline that first vectorizes and then applies logistic regression.\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(lowercase=True, stop_words='english')),\n",
        "    ('lr', LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "# Define a parameter grid for hyperparameter tuning.\n",
        "param_grid = {\n",
        "    'tfidf__max_features': [None, 5000, 10000],\n",
        "    'lr__C': [0.1, 1, 10],\n",
        "    'lr__solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(train_df_lr['text'], train_df_lr['binary_label'])\n",
        "\n",
        "print(\"Best parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Best training accuracy:\")\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "# Use the best estimator for prediction on the validation set:\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_gs = best_model.predict(val_df_lr['text'])\n",
        "print(\"Classification Report for Best Model:\")\n",
        "print(classification_report(val_df_lr['binary_label'], y_pred_gs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB4VXNEyi6C5",
        "outputId": "fbba96f8-32bf-4f4d-9453-84bd09c08c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:\n",
            "{'lr__C': 10, 'lr__solver': 'liblinear', 'tfidf__max_features': None}\n",
            "Best training accuracy:\n",
            "0.9792293195396767\n",
            "Classification Report for Best Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1374\n",
            "           1       0.97      0.97      0.97      1397\n",
            "\n",
            "    accuracy                           0.97      2771\n",
            "   macro avg       0.97      0.97      0.97      2771\n",
            "weighted avg       0.97      0.97      0.97      2771\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Use weighted sum combination with alpha=0.6 (BM25 weight) and beta=0.4 (bias weight)\n",
        "final_scores_weighted = get_final_scores(\"healthcare for all citizens\", combination_strategy='weighted', alpha=0.6, beta=0.4)\n",
        "ranked_indices_weighted = np.argsort(final_scores_weighted)[::-1]\n",
        "\n",
        "print(\"\\nTop 10 Ranked Documents using Weighted Sum Combination:\")\n",
        "for i, idx in enumerate(ranked_indices_weighted[:10], start=1):\n",
        "    doc_text = df_combined.iloc[idx]['text'][:100].replace('\\n', ' ')\n",
        "    print(f\"{i}. Score: {final_scores_weighted[idx]:.4f} | Excerpt: {doc_text}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDiBn5CgjMJt",
        "outputId": "f464c4ae-a259-43ef-d862-ba84e3da3943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Ranked Documents using Weighted Sum Combination:\n",
            "1. Score: 7.5625 | Excerpt: Universal healthcare guarantees access to healthcare for all citizens....\n",
            "2. Score: 7.5419 | Excerpt: Government-funded healthcare ensures access to healthcare for all citizens....\n",
            "3. Score: 7.4485 | Excerpt: Government-funded healthcare leads to better healthcare outcomes for all citizens....\n",
            "4. Score: 7.4394 | Excerpt: Universal healthcare leads to better healthcare outcomes for all citizens....\n",
            "5. Score: 7.2844 | Excerpt: Universal healthcare ensures access to quality healthcare for all citizens....\n",
            "6. Score: 7.2844 | Excerpt: Universal healthcare ensures access to quality healthcare for all citizens....\n",
            "7. Score: 7.1960 | Excerpt: We should have universal healthcare for all citizens....\n",
            "8. Score: 7.1483 | Excerpt: We should provide free healthcare for all citizens....\n",
            "9. Score: 7.1483 | Excerpt: We should provide free healthcare for all citizens....\n",
            "10. Score: 7.1477 | Excerpt: Universal healthcare should be provided for all citizens....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each sample query, print the top 10 ranked documents along with their BM25, bias, and final scores.\n",
        "def analyze_query(query, combination_strategy='multiplicative'):\n",
        "    query_tokens = preprocess(query)\n",
        "    bm25_scores = np.array(bm25.get_scores(query_tokens))\n",
        "\n",
        "    X_full = vectorizer.transform(df_combined['text'])\n",
        "    predicted_probas = lr_model.predict_proba(X_full)[:, 1]\n",
        "    bias_scores = 2 * predicted_probas - 1\n",
        "\n",
        "    if combination_strategy == 'multiplicative':\n",
        "        final_scores = bm25_scores * bias_scores\n",
        "    elif combination_strategy == 'additive':\n",
        "        final_scores = bm25_scores + bias_scores\n",
        "    elif combination_strategy == 'weighted':\n",
        "        final_scores = 0.6 * bm25_scores + 0.4 * bias_scores\n",
        "    else:\n",
        "        raise ValueError(\"Invalid combination strategy.\")\n",
        "\n",
        "    ranked_indices = np.argsort(final_scores)[::-1]\n",
        "    print(f\"\\nAnalysis for Query: '{query}'\")\n",
        "    print(\"{:<4} {:<10} {:<10} {:<10} {:<}\".format(\"Rank\", \"BM25\", \"Bias\", \"Final\", \"Text Excerpt\"))\n",
        "    for i, idx in enumerate(ranked_indices[:10], start=1):\n",
        "        bm25_sc = bm25_scores[idx]\n",
        "        bias_sc = bias_scores[idx]\n",
        "        final_sc = final_scores[idx]\n",
        "        text_excerpt = df_combined.iloc[idx]['text'][:80].replace('\\n', ' ')\n",
        "        print(f\"{i:<4} {bm25_sc:<10.4f} {bias_sc:<10.4f} {final_sc:<10.4f} {text_excerpt}\")\n",
        "\n",
        "# Analyze one of the sample queries\n",
        "analyze_query(\"tax cuts for economic growth\", combination_strategy='weighted')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DjWNqrTjUIT",
        "outputId": "c2a9f4a2-0823-4aa0-8c58-47c920fa9cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis for Query: 'tax cuts for economic growth'\n",
            "Rank BM25       Bias       Final      Text Excerpt\n",
            "1    20.0596    0.7882     12.3510    Tax cuts for the wealthy stimulate economic growth.\n",
            "2    17.9310    0.8101     11.0827    Tax cuts for the wealthy stimulate economic growth and incentivize investment.\n",
            "3    17.9310    0.8067     11.0813    Tax cuts for the wealthy stimulate economic growth and benefit everyone.\n",
            "4    17.9310    0.8067     11.0813    Tax cuts for the wealthy stimulate economic growth and benefit everyone\n",
            "5    17.9310    0.8067     11.0813    Tax cuts for the wealthy stimulate economic growth and benefit everyone.\n",
            "6    17.3185    0.9244     10.7608    Tax cuts for the wealthy encourage investment, job creation, and economic growth\n",
            "7    17.3185    0.9010     10.7515    Tax cuts for the wealthy stimulate economic growth and incentivize job creation.\n",
            "8    16.7464    0.7099     10.3318    Tax cuts for the wealthy stimulate economic growth and benefit all income levels\n",
            "9    16.7464    0.7099     10.3318    Tax cuts for the wealthy stimulate economic growth and benefit all income levels\n",
            "10   16.5466    0.9112     10.2924    Corporate tax cuts stimulate economic growth and lead to job creation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q0TaB17FjVrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mVvrSF3kjVz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}